# Cognitive Providers Introduction

## Introduction

{% include from="B03-08_0701-Cog-Prov-Intro.md" element-id="B03-08_0701-Cog-Prov-Intro_snippet" /%}

To use OpenAI and Azure OpenAI you must have a valid API key and other details. If needed, Amelia staff can provide configuration help with these details.

Once you configure an LLM connection, you can test the connection. If you configure many LLMs, you also can set one as the default. The other configurations then map to specific features. To use more than one LLM, use different model names (OpenAI) or deployments (Azure OpenAI). When using the internal LLM service, you don't need more than one configuration. The internal LLM operates based on the type of task.

See our [Cognitive Providers Management](B03-08-NLU-Resources_B03-08_0301-Response-Pools-Intro.md) topic for details about using this feature.

## What You'll Learn

In this topic you'll learn about:accessing the Cognitive Providers workspace.

## Accessing the Cognitive Providers Workspace

{% include from="B03-08_0703-CognitiveProvAccess.md" element-id="B03-08_0703-CognitiveProvAccess_snippet" /%}

## More Resources

For more information, see:

* [Cognitive Providers Management](B03-08_0703-Cog-Provider-Mgmt.md).

* [NLU Resources Introduction](B03-08_0002-NLU-Resources-Intro.md).

